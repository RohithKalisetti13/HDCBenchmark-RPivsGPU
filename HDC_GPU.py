# -*- coding: utf-8 -*-
"""Final _code forgpu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PndQdauXQYX_9QB7dPKHrhvPxNDrgBDp
"""

pip install git+https://github.com/hyperdimensional-computing/torchhd.git

!pip install torchmetrics

!pip install nvidia-ml-py
import psutil
import pynvml

!pip install thop
from thop import profile
from thop import clever_format

pip install git+https://github.com/hyperdimensional-computing/torchhd.git

# Install necessary libraries
#!pip install torchmetrics torchhd



# Import libraries
import torchmetrics
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import torchhd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision.datasets import MNIST
import pynvml
import time
from torchhd.models import Centroid
from torchhd import embeddings

# Use the GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using {} device".format(device))

# NVML Setup
pynvml.nvmlInit()

# GPU Information Function
def get_gpu_info():
    """Retrieve and display GPU information."""
    pynvml.nvmlInit()
    handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # Handle for GPU 0
    gpu_name = pynvml.nvmlDeviceGetName(handle)
    gpu_temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
    gpu_power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000  # Convert to watts
    gpu_memory = pynvml.nvmlDeviceGetMemoryInfo(handle)
    print(f"GPU Name: {gpu_name}")
    print(f"Temperature: {gpu_temperature} Â°C")
    print(f"Power Usage: {gpu_power:.2f} W")
    print(f"Memory Usage: {gpu_memory.used / 1024**2:.2f} MB / {gpu_memory.total / 1024**2:.2f} MB")

# Retrieve Current Energy Usage
def get_current_energy():
    """Retrieve the current energy usage of the GPU in millijoules (mJ)."""
    handle = pynvml.nvmlDeviceGetHandleByIndex(0)
    return pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)

def measure_performance(func, *args, **kwargs):
    """Measure time, memory, and energy for a function."""
    # Start measurements
    start_energy = get_current_energy()
    torch.cuda.reset_peak_memory_stats()  # Reset peak memory stats
    start_time = time.time()

    # Execute the function
    result = func(*args, **kwargs)

    # End measurements
    end_energy = get_current_energy()
    end_time = time.time()

    # Calculate metrics
    energy_consumed = end_energy - start_energy
    time_elapsed = end_time - start_time
    peak_memory_used = torch.cuda.max_memory_allocated() / 1024**2  # Peak memory in MB

    print(f"Energy Consumed: {energy_consumed} mJ")
    print(f"Time Elapsed: {time_elapsed:.2f} seconds")
    print(f"Peak Memory Used: {peak_memory_used:.2f} MB")

    return result

# Hyperparameters
DIMENSIONS = 5000
IMG_SIZE = 28
NUM_LEVELS = 1000
BATCH_SIZE = 1                                                                           # for GPUs with enough memory we can process multiple images at once

# Define Encoder
class Encoder(nn.Module):
    def __init__(self, out_features, size, levels):
        super(Encoder, self).__init__()
        self.flatten = torch.nn.Flatten()
        self.position = embeddings.Random(size * size, out_features)
        self.value = embeddings.Level(levels, out_features)

    def forward(self, x):
        x = self.flatten(x)
        sample_hv = torchhd.bind(self.position.weight, self.value(x))
        sample_hv = torchhd.multiset(sample_hv)
        return torchhd.hard_quantize(sample_hv)

# Prepare the dataset and dataloaders
transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])
train_ds = MNIST(root="./data", train=True, download=True, transform=transform)
test_ds = MNIST(root="./data", train=False, download=True, transform=transform)
train_ld = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)
test_ld = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)

# Initialize Encoder and Model
encode = Encoder(DIMENSIONS, IMG_SIZE, NUM_LEVELS).to(device)
num_classes = len(train_ds.classes)
model = Centroid(DIMENSIONS, num_classes).to(device)

# Training Function
def train():
    with torch.no_grad():
        for samples, labels in tqdm(train_ld, desc="Training"):
            samples = samples.to(device)
            labels = labels.to(device)

            samples_hv = encode(samples)
            model.add(samples_hv, labels)

# Testing Function
def test():
    accuracy = torchmetrics.Accuracy("multiclass", num_classes=num_classes)
    with torch.no_grad():
        model.normalize()
        for samples, labels in tqdm(test_ld, desc="Testing"):
            samples = samples.to(device)
            samples_hv = encode(samples)
            outputs = model(samples_hv, dot=True)
            accuracy.update(outputs.cpu(), labels)
    acc = accuracy.compute().item() * 100
    print(f"Testing accuracy: {acc:.3f}%")

# Display GPU Info
print("GPU Information:")
get_gpu_info()

# Train the Model
print("\nTraining the model...")
measure_performance(train)

# Test the Model
print("\nTesting the model...")
measure_performance(test)